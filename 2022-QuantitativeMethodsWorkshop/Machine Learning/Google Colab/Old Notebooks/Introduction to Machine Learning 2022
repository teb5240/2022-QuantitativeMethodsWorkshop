{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to Machine Learning 2022","provenance":[{"file_id":"1f0Yn3ctWYgK2Gwc4zCyuCekRYPjQpaWb","timestamp":1618497666186}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2FH70a-o3tfk"},"source":["# Introduction to Machine Learning\n","This tutorial was composed by Taylor Baum with adaptations from the National Science Foundation (NSF) Center for Brains, Minds and Machines Quantitative Methods Workshop and [2].\n","\n","## Introduction\n","\n","An **algorithm** is similar to a recipe. More formally, an **algorithm** is a process or set of rules with which a task is completed or with which an input is manipulated to produce an output. For example, we use algorithms for tasks like sorting. \n","\n","What if there is a task where the algorithm isn’t obvious? What can we do? Well, we often have a large amount of data that we can use to help inform how we produce appropriate outputs from these inputs. As beautifully defined in [1], \"Machine Learning provides automated methods of data analysis that can then be used further. Machine Learning is a set of methods that can automatically detect patterns in data, and then use the uncovered patterns to predict future data, or to perform other kinds of decision making under uncertainty.\"\n","\n","\n","## Where did the idea for Machine Learning come from?\n","\n","Traditionally, humans learn how to do certain tasks from experience in the real-world while computers must be instructed to do things. Machine learning is a field which seeks to enable computers and machines to learn from experience. The experience that computers have access to is known as data. \n","\n","Thus far, there are three different ways that a machine can learn: **supervised learning**, **unsupervised learning**, and **reinforcement learning**. We will focus on the first two methods.\n","\n","**Supervised learning** uses **labeled** data as it’s feature set or the data we initially have to learn patterns from. The labeled data is a set of input-output pairs. In other words, you have input variables (X) and their corresponding output variables (Y) and you want to learn the mapping between these variables.\n","\n","**Unsupervised learning** uses **unlabeled** data as it’s feature set or the data we initially have to learn patterns from. In **unsupervised learning**, we only have a set of inputs, and the goal is to discover interesting patterns in the data.\n","\n","Some examples of achievements which are direct results of the benefits of machine learning are AlphaGo, a system which can outperform a champion Go player, face detection on the iPhone, and various object detection paradigms. In the past three examples, we see that these tasks are complex, like a game with many rules. Before Machine Learning approaches, progress towards achieving these tasks was minimal.\n","\n","## How do we learn from data?\n","\n","To get an understanding of how patterns and relationships may be uncovered in data to then be used for future predictions or decision making, let's dive into some interactive examples.\n","\n","Each case where we want to use machine learning is unique, but can be boiled down into a few main components:\n","\n","1. Identify the input/output relationship you want to understand\n","2. Identify an approximate model from patterns in the data that explains this relationship\n","3. Verify the quality of your model\n","4. Use the model to predict future data or influence future decisions\n","\n","We will learn that these four steps are useful to guide the development of many machine learning models. We can expand these steps to more specifically reference certain problem spaces, however, these four underlying steps will still be present.\n","\n","First, we will look at an example of **supervised learning**, where we have a set of input/output pairs and we would like to find a relationship between these inputs and outputs. We will use a very simple synthetic data set."]},{"cell_type":"markdown","metadata":{"id":"iloUoj-452cb"},"source":[""]},{"cell_type":"code","metadata":{"id":"k1GUGrjw0fWT"},"source":["import numpy as np # a package for manipulating numbers and using arrays\n","from sklearn.linear_model import LinearRegression # a package with an optimized LinearRegression class\n","import matplotlib.pyplot as plt # a package with plotting capabilities"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9LETHt0M6Vhb"},"source":["### Step 2: Provide Data\n","\n","Next we load and prepare our data. In this case, we are using synthetic data, so there is not much we need to do!"]},{"cell_type":"code","metadata":{"id":"WGmI3Rg46Qve","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636429508356,"user_tz":300,"elapsed":245,"user":{"displayName":"Taylor Baum","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16126157927038755382"}},"outputId":"4b4f7889-40ee-4fbe-a9f9-3272d29d3c00"},"source":["x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1)) # synthetic x-data\n","y = np.array([5, 20, 14, 32, 22, 38]) # synthetic y-data\n","\n","# Use these commands to look at the arrays after the .reshape function\n","print(x)\n","print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 5]\n"," [15]\n"," [25]\n"," [35]\n"," [45]\n"," [55]]\n","[ 5 20 14 32 22 38]\n"]}]},{"cell_type":"markdown","metadata":{"id":"HEekXn1w6bpF"},"source":["### Step 3: Create and Fit the Model\n","\n","Next, we take advantage of the `LinearRegression()` class that we downloaded from the `sklearn` package. First, we create an instance of the `LinearRegression()` class. Next, we use the `.fit(x,y)` method from this class."]},{"cell_type":"code","metadata":{"id":"6fRhWqZo6aMV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636429509431,"user_tz":300,"elapsed":340,"user":{"displayName":"Taylor Baum","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16126157927038755382"}},"outputId":"5e4a0f4d-5924-42bb-c758-6e4e5e542285"},"source":["model = LinearRegression() # this line is creating an instance of the class LinearRegression\n","model.fit(x, y) # this line is using a method within the LinearRegression class which fits the model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"C3u60Uw_6gWu"},"source":["We can actually condense these first two lines to one line, and get an equivalent output! These types of shortcuts make more sense the more one attemtps their own projects."]},{"cell_type":"code","metadata":{"id":"jCifeK2x6img"},"source":["model = LinearRegression().fit(x, y) # syntactically, this line is equivalent to the two lines above"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_l6fQgAE6sFh"},"source":["### Step 4: Get Results\n","\n","After fitting the model, we would like to explore the results and performance of the model! There are many values we can derive which describe characteristics of our fit. \n","\n","$r$, a value between -1 and 1, is the **correlation coefficient**, which will be defined in the tutorial. Values further from 0 indicate a stronger relationship between the two variables.\n","\n","To derive $r$, we use the function below. Sometimes this function is already coded in packages. We will see that the `.score(x, y)` function outputs the $r^2$ value.\n","\n","$r = \\frac{1}{n-1}\\sum\\limits_{i}^{n}{\\frac{x_i-\\bar{x}}{s_x} \\frac{y_i-\\bar{y}}{s_y}}$\n","\n","where $\\bar{x}$, $\\bar{y}$, $s_x$ and $s_y$ are the respecive means and standard deviations of the respective variables. \n","\n","$r^2$, ranging from 0 to 1, is the **coefficient of determination**. This is equal to the proportion of the total variability explained by the model. An $r^2$ of 0 means that the dependent variable cannot be predicted from the independent variable. An $r^2$ of 1 means the dependent variable can be predicted without error from the independent variable. To get a deeper look into the underlying mathematics, please reference [5]."]},{"cell_type":"code","metadata":{"id":"cIl2EHv26kLS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636429513364,"user_tz":300,"elapsed":181,"user":{"displayName":"Taylor Baum","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16126157927038755382"}},"outputId":"19bf347e-048a-4bc0-da5b-438805926659"},"source":["x = model.score(x, y) # this line helps show us how good our model is\n","print('coefficient of determination:', y) # print the model score"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["coefficient of determination: [ 5 20 14 32 22 38]\n"]}]},{"cell_type":"markdown","metadata":{"id":"d2MuzvcC6wCp"},"source":["From using this `LinearRegression()` class and its method `.fit(x, y)` we have output model which has different methods. Above, we looked at the method `.score(x, y)` which output the $r^2$ value for this set of input output pairs with this trained model.\n","\n","Below, we extract the learned y-intercept, and slope. We can use these values to then predict unknown input/output pairs in the future!"]},{"cell_type":"code","metadata":{"id":"UhYsbfsG65mE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636429516416,"user_tz":300,"elapsed":8,"user":{"displayName":"Taylor Baum","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16126157927038755382"}},"outputId":"b1d057ab-6168-47d5-f9d9-aaa520358361"},"source":["print('intercept:', model.intercept_) # print the y-intercept\n","print('slope:', model.coef_) # print the slope"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["intercept: 5.633333333333329\n","slope: [0.54]\n"]}]},{"cell_type":"markdown","metadata":{"id":"4Orfm43567on"},"source":["### Step 5: Make Predictions\n","\n","After fitting the model, we would now like to visualize the results and then use the results to predict future outputs of new inputs."]},{"cell_type":"code","metadata":{"id":"Ph4y2MAXCCXq","colab":{"base_uri":"https://localhost:8080/","height":133},"executionInfo":{"status":"error","timestamp":1636429521115,"user_tz":300,"elapsed":177,"user":{"displayName":"Taylor Baum","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16126157927038755382"}},"outputId":"ed7ebde8-52d3-46d8-d3f1-49473e52fccd"},"source":["plt.style.use('ggplot') # we use the style 'ggplot' because it is pretty\n","\n","plt.plot([REPLACE ME], y, 'ko') # plot the original data in black ('k') circles ('o')\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-f7c62add6fb2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    plt.plot([REPLACE ME], y, 'ko') # plot the original data in black ('k') circles ('o')\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"uYuGVVwX6-bb"},"source":["plt.style.use('ggplot') # we use the style 'ggplot' because it is pretty\n","\n","plt.plot(x, [REPLACE ME], 'ko') # plot the original data in black ('k') circles ('o')\n","\n","x_test = np.array([10, 12, 37, 10.4, 5, 57]).reshape((-1, 1)) # synthetic x-data\n","print(x_test)\n","\n","y_pred_package = model.predict([REPLACE ME]) # use a predefined method to predict outputs from a set of inputs\n","print('predicted response from package:', y_pred_package, sep='\\n') # print prediction results\n","plt.plot(x_test, y_pred_package, 'r') # plot the learned relationship in a red ('r') line (default)\n","\n","# it is crucial to always fully annotate your plots\n","plt.xlabel('X-Data (Unit)')\n","plt.ylabel('Y-Data (Unit)')\n","plt.title('Linear Regression')    \n","plt.legend(['training data', 'learned model'])   \n","plt.show() # show the plot generated for each case"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"js4iiSKd7AW9"},"source":["Above, we used a built-in function `.predict` to generate our estimated outputs from our learned relationship or the results from the model fit. To show that we understand what we just completed, however, we can verify. that using the parameters we solved for by replacing them in the model equation. If this gives us the same result, then we know that we have a deep understanding of the model!\n","\n","We know that $y = mx + b$ is the model that we are trying to fit. We solved for the y-intercept or $b$, along with the slope or $m$. Using our learned paramters, we can generate our predictions by coding the equation by hand, as shown below."]},{"cell_type":"code","metadata":{"id":"axpZ1_jl7CLh"},"source":["plt.plot(x, y, 'ko') # plot the original data in black ('k') circles ('o')\n","\n","x_test = np.array([10, 12, 37, 10.4, 5, 57]).reshape((-1, 1)) # synthetic x-data\n","print(x_test)\n","\n","y_pred_user = (model.coef_ * x_test) + [REPLACE ME] # generate the same predicted relationship using parameters\n","print('predicted response from user:', y_pred_package, sep='\\n') # print prediction\n","plt.plot(x_test, y_pred_user, 'ro') # plot the learned relationship in a red ('r') line (default)\n","\n","# it is crucial to always fully annotate your plots\n","plt.xlabel('X-Data (Unit)')\n","plt.ylabel('Y-Data (Unit)')\n","plt.title('Linear Regression')    \n","plt.legend(['training data', 'learned model'])   \n","plt.show() # show the plot generated for each case"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jqcrr_60kDNV"},"source":["# Sources\n","1. Murphy, Kevin P.. Machine Learning: A Probabilistic Perspective, MIT Press, 2012. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/pensu/detail.action?docID=3339490.\n","2. https://realpython.com/linear-regression-in-python/#linear-regression\n","https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/linear_model/base.py#L367"]}]}